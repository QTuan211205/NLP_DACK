import pandas as pd
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer, util
from py2neo import Graph
import google.generativeai as genai
import numpy as np

# ==========================================
# 1. Cáº¤U HÃŒNH
# ==========================================
GOOGLE_API_KEY = "".strip()
genai.configure(api_key=GOOGLE_API_KEY)
model_gemini = genai.GenerativeModel('models/gemini-2.5-flash')

# Káº¿t ná»‘i Neo4j
try:
    graph = Graph("bolt://127.0.0.1:7687", auth=("neo4j", "12345678"))
    print("âœ… ÄÃ£ káº¿t ná»‘i Neo4j!")
except:
    print("âŒ KhÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c Neo4j. HÃ£y báº­t Neo4j Desktop!")
    exit()

# ==========================================
# 2. CHUáº¨N Bá»Š Dá»® LIá»†U TÃŒM KIáº¾M (INDEXING)
# ==========================================
print("â³ Äang táº£i dá»¯ liá»‡u vÃ  khá»Ÿi táº¡o mÃ´ hÃ¬nh tÃ¬m kiáº¿m...")

# Load dá»¯ liá»‡u gá»‘c Ä‘á»ƒ lÃ m danh sÃ¡ch tÃ¬m kiáº¿m (Search Corpus)
# ÄÆ°á»ng dáº«n nÃ y trá» Ä‘áº¿n file CSV báº¡n dÃ¹ng Ä‘á»ƒ import Neo4j
df = pd.read_csv(r'..\data\data_translated.csv', encoding='utf-8')

# ChÃºng ta sáº½ tÃ¬m kiáº¿m trÃªn cá»™t 'tÃªn_bá»‡nh' (Entity Name)
# Náº¿u báº¡n muá»‘n tÃ¬m cáº£ thuá»‘c, hÃ£y gá»™p thÃªm danh sÃ¡ch thuá»‘c vÃ o Ä‘Ã¢y
corpus = df['tÃªn_bá»‡nh'].dropna().unique().tolist()
corpus = [str(x).strip() for x in corpus if str(x).strip()]

# --- A. Cáº¥u hÃ¬nh Vector Search (Semantic) ---
# DÃ¹ng model nhá» gá»n há»— trá»£ tiáº¿ng Viá»‡t tá»‘t
embedder = SentenceTransformer('keepitreal/vietnamese-sbert') 
corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)

# --- B. Cáº¥u hÃ¬nh Keyword Search (BM25) ---
# TÃ¡ch tá»« Ä‘Æ¡n giáº£n báº±ng khoáº£ng tráº¯ng (cÃ³ thá»ƒ dÃ¹ng pyvi náº¿u muá»‘n chuáº©n hÆ¡n)
tokenized_corpus = [doc.lower().split(" ") for doc in corpus]
bm25 = BM25Okapi(tokenized_corpus)

print(f"âœ… ÄÃ£ index xong {len(corpus)} thá»±c thá»ƒ bá»‡nh.")

# ==========================================
# 3. THUáº¬T TOÃN HYBRID SEARCH (RRF)
# ==========================================
def hybrid_search(query, top_k=3):
    """
    Káº¿t há»£p Vector Search vÃ  BM25 báº±ng thuáº­t toÃ¡n Reciprocal Rank Fusion (RRF)
    """
    # 1. Vector Search Results
    query_embedding = embedder.encode(query, convert_to_tensor=True)
    # Láº¥y top 10 vector
    search_hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=10)[0]
    
    # 2. BM25 Search Results
    tokenized_query = query.lower().split(" ")
    # Láº¥y top 10 BM25 (tráº£ vá» danh sÃ¡ch text, cáº§n map ngÆ°á»£c láº¡i index)
    bm25_scores = bm25.get_scores(tokenized_query)
    bm25_top_n = np.argsort(bm25_scores)[::-1][:10]
    
    # 3. RRF Fusion (TÃ­nh Ä‘iá»ƒm xáº¿p háº¡ng)
    # CÃ´ng thá»©c: score = 1 / (k + rank)
    rrf_score = {}
    k = 60 # Háº±ng sá»‘ thÆ°á»ng dÃ¹ng trong RRF
    
    # Cá»™ng Ä‘iá»ƒm tá»« Vector
    for rank, hit in enumerate(search_hits):
        doc_idx = hit['corpus_id']
        rrf_score[doc_idx] = rrf_score.get(doc_idx, 0) + (1 / (k + rank + 1))
        
    # Cá»™ng Ä‘iá»ƒm tá»« BM25
    for rank, doc_idx in enumerate(bm25_top_n):
        rrf_score[doc_idx] = rrf_score.get(doc_idx, 0) + (1 / (k + rank + 1))
        
    # Sáº¯p xáº¿p láº¡i theo Ä‘iá»ƒm RRF cao nháº¥t
    sorted_rrf = sorted(rrf_score.items(), key=lambda x: x[1], reverse=True)
    
    # Láº¥y top_k káº¿t quáº£ cuá»‘i cÃ¹ng
    final_results = []
    for doc_idx, score in sorted_rrf[:top_k]:
        final_results.append(corpus[doc_idx])
        
    return final_results

# ==========================================
# 4. TRUY Váº¤N GRAPH & SINH CÃ‚U TRáº¢ Lá»œI
# ==========================================
def get_graph_context(disease_name):
    """
    Khi Ä‘Ã£ biáº¿t chÃ­nh xÃ¡c tÃªn bá»‡nh, truy váº¥n tháº³ng vÃ o Neo4j
    """
    query = f"""
    MATCH (b:`Bá»†NH` {{tÃªn_bá»‡nh: "{disease_name}"}})
    OPTIONAL MATCH (b)-[:`CÃ“ TRIá»†U CHá»¨NG`]->(tc:`TRIá»†U CHá»¨NG`)
    OPTIONAL MATCH (b)-[:`ÄIá»€U TRá»Š VÃ€ PHÃ’NG TRÃNH CÃ™NG`]->(lk:`Lá»œI KHUYÃŠN`)
    OPTIONAL MATCH (b)-[:`ÄÆ¯á»¢C KÃŠ ÄÆ N`]->(t:`THUá»C`)
    OPTIONAL MATCH (b)-[:`ÄÆ¯á»¢C CHá»®A Bá»I`]->(dt:`ÄIá»€U TRá»Š`)
    RETURN b, tc, lk, t, dt
    """
    return graph.run(query).data()

def generate_answer(user_question, context_data, disease_found):
    prompt = f"""
    Báº¡n lÃ  bÃ¡c sÄ© AI. NgÆ°á»i dÃ¹ng Ä‘ang há»i vá»: "{user_question}"
    Há»‡ thá»‘ng tÃ¬m kiáº¿m Ä‘Ã£ xÃ¡c Ä‘á»‹nh bá»‡nh liÃªn quan nháº¥t lÃ : "{disease_found}"
    
    Dá»¯ liá»‡u chi tiáº¿t tá»« Knowledge Graph:
    {context_data}
    
    HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn dá»¯ liá»‡u trÃªn. Náº¿u dá»¯ liá»‡u khÃ´ng Ä‘á»§, hÃ£y nÃ³i rÃµ.
    """
    response = model_gemini.generate_content(prompt)
    return response.text

# ==========================================
# 5. CHáº Y CHÆ¯Æ NG TRÃŒNH
# ==========================================
if __name__ == "__main__":
    print("\nğŸš€ Há»† THá»NG HYBRID RAG ÄÃƒ Sáº´N SÃ€NG!")
    print("MÃ´ hÃ¬nh nÃ y káº¿t há»£p tÃ¬m kiáº¿m Vector + Tá»« khÃ³a Ä‘á»ƒ tÃ¬m Ä‘Ãºng tÃªn bá»‡nh trÆ°á»›c khi tra cá»©u.")
    
    while True:
        question = input("\nğŸ‘¤ Báº¡n há»i: ")
        if question.lower() in ['exit', 'quit']: break
        
        # B1: Hybrid Search Ä‘á»ƒ tÃ¬m thá»±c thá»ƒ (Entity Linking)
        top_matches = hybrid_search(question, top_k=1)
        
        if not top_matches:
            print("ğŸ¤– Bot: Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y tÃªn bá»‡nh nÃ o khá»›p trong dá»¯ liá»‡u.")
            continue
            
        best_match = top_matches[0]
        print(f"ğŸ” Há»‡ thá»‘ng xÃ¡c Ä‘á»‹nh chá»§ Ä‘á»: '{best_match}'")
        
        # B2: Láº¥y dá»¯ liá»‡u Graph
        context = get_graph_context(best_match)
        
        # B3: Gemini tráº£ lá»i
        if context:
            answer = generate_answer(question, context, best_match)
            print(f"ğŸ¥ Bot Ä‘Ã¡p: {answer}")
        else:
            print(f"ğŸ¤– Bot: TÃ¬m tháº¥y tÃªn bá»‡nh '{best_match}' nhÆ°ng chÆ°a cÃ³ dá»¯ liá»‡u chi tiáº¿t trong Graph.")