import os
import google.generativeai as genai
from dotenv import load_dotenv

# ========================================================
# 1. T·ª∞ ƒê·ªòNG C·∫§U H√åNH (Auto-Config)
# ========================================================

# T·ª± ƒë·ªông t√¨m file key.env ·ªü th∆∞ m·ª•c g·ªëc (l√πi ra 2 c·∫•p t·ª´ preprocessing/kgraph)
current_dir = os.path.dirname(os.path.abspath(__file__))
env_path = os.path.join(current_dir, '..', '..', 'key.env')

# N·∫øu kh√¥ng th·∫•y, th·ª≠ t√¨m ·ªü c·∫•p cha g·∫ßn nh·∫•t (l√πi 1 c·∫•p)
if not os.path.exists(env_path):
    env_path = os.path.join(current_dir, '..', 'key.env')

# ƒê·ªçc file .env
load_dotenv(env_path)

# L·∫•y API Key
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    # Key d·ª± ph√≤ng (Fallback) n·∫øu file .env b·ªã l·ªói ho·∫∑c ch∆∞a t·∫°o
    print("‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c key.env")

# C·∫•u h√¨nh Gemini
genai.configure(api_key=GOOGLE_API_KEY.strip())

# --- THAY ƒê·ªîI THEO Y√äU C·∫¶U: D√πng Model 2.0 Flash ---
MODEL_NAME = "models/gemini-2.0-flash"

# ========================================================
# 2. C·∫§U H√åNH THAM S·ªê (Generation Config)
# ========================================================
generation_config = {
  "temperature": 0,       # Nhi·ªát ƒë·ªô = 0 ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c, kh√¥ng b·ªãa
  "top_p": 1,
  "top_k": 1,
  "max_output_tokens": 50000,
}

safety_settings = [
  {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
  {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
  {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
  {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"}
]

# Kh·ªüi t·∫°o Model
try:
    model = genai.GenerativeModel(model_name=MODEL_NAME,
                                  generation_config=generation_config,
                                  safety_settings=safety_settings)
except Exception as e:
    print(f"‚ùå L·ªói kh·ªüi t·∫°o Model {MODEL_NAME}: {e}")

# ========================================================
# 3. C√ÅC H√ÄM GIAO TI·∫æP (API Wrappers - Gi·ªØ nguy√™n t√™n h√†m g·ªëc)
# ========================================================

def get_GPT(text):
    """
    H√†m n√†y t√™n l√† GPT (ƒë·ªÉ kh·ªõp v·ªõi code c≈© c·ªßa t√°c gi·∫£),
    nh∆∞ng th·ª±c t·∫ø s·∫Ω g·ªçi Gemini ƒë·ªÉ b·∫°n kh√¥ng m·∫•t ti·ªÅn OpenAI.
    """
    return get_gemini(text)
 
def get_gemini(text): 
    """
    H√†m g·ªçi Gemini ch√≠nh.
    """
    try:
        # G·ªçi API sinh n·ªôi dung
        response = model.generate_content([text])
        return response.text
    except Exception as e:
        # X·ª≠ l√Ω l·ªói n·∫øu Google ch·∫∑n ho·∫∑c h·∫øt quota
        err_msg = str(e)
        if "429" in err_msg or "Quota" in err_msg:
            return "L·ªói: H·∫øt Quota (Limit Exceeded). Vui l√≤ng th·ª≠ l·∫°i sau."
        return f"L·ªói Gemini: {err_msg}"

# ========================================================
# 4. CH·∫†Y TEST NHANH
# ========================================================
if __name__ == "__main__":
    print(f"--- ƒêang test llm.py ---")
    print(f"‚úÖ Model ƒëang d√πng: {MODEL_NAME}")
    print(f"üîë Key ƒëang d√πng: ...{GOOGLE_API_KEY[-5:]}")
    
    while True:
        q = input("\nB·∫°n h·ªèi (g√µ 'exit' ƒë·ªÉ tho√°t): ")
        if q.lower() in ['exit', 'quit']: break
        
        print("Bot ƒë√°p:", get_gemini(q))